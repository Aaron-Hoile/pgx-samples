# entity-linking
Repository for the Entity Linking project.

Check out our paper at: https://dl.acm.org/citation.cfm?id=3328499

# Data
Data can be obtained from [DBPedia](http://wiki.dbpedia.org/downloads-2016-10).

Dataset used in graph generation:
* [Labels](http://downloads.dbpedia.org/2016-04/core-i18n/en/labels_en.ttl.bz2): list of all DBPedia resources/pages, used to obtain the vertices of the graph.
* [Mapped Infobox Properties](http://downloads.dbpedia.org/2016-10/core-i18n/en/infobox_properties_en.ttl.bz2): property values used in Wikipedia Infoboxes. 
* [Instance Types](http://downloads.dbpedia.org/2016-10/core-i18n/en/instance_types_en.ttl.bz2): type of each DBPedia/Wikipedia resource.
* [Mappingbased Objects](http://downloads.dbpedia.org/2016-04/core-i18n/en/mappingbased_objects_en.ttl.bz2): ontology links between resources.
* [Mappingbased Literals](http://downloads.dbpedia.org/2016-04/core-i18n/en/mappingbased_literals_en.ttl.bz2): literal values of ontology relations. Literals are used only if they can be mapped to DBPedia resources.
* [Redirects](http://downloads.dbpedia.org/2016-04/core-i18n/en/redirects_en.ttl.bz2): redirect links between resources. Used to enrich the candidate finder.
* [Wikipedia Links](http://downloads.dbpedia.org/2016-04/core-i18n/en/wikipedia_links_en.ttl.bz2): mapping between DBPedia and Wikipedia pages.
* [Disambiguations](http://downloads.dbpedia.org/2016-10/core-i18n/en/disambiguations_en.ttl.bz2): list of disambiguation pages, and links to the pages they point to. Used to enrich the candidate finder.
* [Internal Page Links](http://downloads.dbpedia.org/2016-10/core-i18n/en/page_links_en.ttl.bz2): list of all links between wikipedia pages. Only edges that do no appear as redirects or disambiguation are considered.

The mapped dataset contains only entities which have at least an edge going to another resource,
while the non-mapped one contains all vertices. For our current goal, the non-mapped dataset is to be preferred.

Data should be placed in `data/graph_data/original` and decompressed.

# Starting the server

1. Create a graph starting from the DBpedia data. For example, use the `create_graph_full_pagelinks.sh` script in the Python folder.
2. Preprocess the graph, for example using `./gradlew runPreprocess --args="-g graph -i path/to/graph.json -p -n 100`.
3. Create the embeddings: `./gradlew createEmbeddings --args="-g graph_p -i data/graph_data/graph.json"` (change parameters directly in the Scala code).
4. Finally, start the server: `./gradlew runEL --args="-g data/graph_data/graph_disambiguation.json -e data/embeddings/embeddings.csv -d 128"`

# A WORD OF CAUTION

The *candidate finder* module has been replaced with a simplified version that uses [Fuzzywuzzy](https://github.com/xdrop/fuzzywuzzy). 
As such, it is slower and less accurate than our original index-based fuzzy string matching. You are encouraged to try other solutions, e.g. Lucene!

# REST API:

Usage example: `http://my.server:4567/link?name=pynkfloyd&name=wall&name=rock&skip-disambiguation=false`

* `num-candidates`: set the maximum number of candidates to use.
    
* `input-weight`: set the input weight. High values are better when partial text is provided.
    
* `min-score`: set the minimum score. High values give faster search, but potentially worse results.
    
* `skip-disambiguation`: skip the disambiguation step.
    
* `optimize-child`: sdd a greedy optimization step to the disambiguation algorithm.

* `max-steps`: set the maximum number of steps done by the disambiguation optimizer.
    
* `early-stop`: set the maximum number of early stopping steps done by the disambiguation optimizer.

* `num-children`: set the number of children generated by the optimizer at each step.
   
* `alpha`: set the alpha parameter, strength of the candidate finder score in the disambiguation.
   
* `beta`: set the beta parameter, stregth of the salience score in the disambiguation.

* `alpha-exp`: set the alpha exponential parameter, power to which candidate finder scores are raised.
    
* `beta-exp`: set the beta exponential parameter, power to which salience scores are raised.

* `init-weight`: set the initial heuristic weight, stregth of the salience score in the heuristic.
    